{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prr7bg1JC89w",
        "outputId": "5e1a1e22-9fe2-4949-e31c-9ad36349ed63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cdcd42897f0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n"
      ],
      "metadata": {
        "id": "_v9XVpBtDSbQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPUj-CKwDUgN",
        "outputId": "2243e24c-b51b-4aab-86b7-0b29d226130b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 83956816.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch6/cifar-10-python.tar.gz to ../data-unversioned/p1ch6/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLm6z6zMDY30",
        "outputId": "c05ea5d2-9221-41e3-eca0-830b66f02f25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_model = nn.Sequential(\n",
        "                nn.Linear(3072, 512),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(512, 10),\n",
        "                nn.LogSoftmax(dim=1))"
      ],
      "metadata": {
        "id": "5lSXeVSEDog9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numel_list = [p.numel() for p in first_model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6csBgtW7DrfL",
        "outputId": "9312f176-7a0e-46d7-f683-937b8c475639"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1578506, [1572864, 512, 5120, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            # ... <1>\n",
        "            nn.Linear(8 * 8 * 8, 32),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(32, 2))"
      ],
      "metadata": {
        "id": "9gsrMlcLEo7f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "LZbEgcy2EsWu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCYFrIKTEwNn",
        "outputId": "44ccf605-7563-4ec7-ce52-be1c164dfb06"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18354, [432, 16, 1152, 8, 16384, 32, 320, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.get_device_properties(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_zLKlevalYN",
        "outputId": "09695d4c-9a77-4cbf-dd2f-abd3106fe51d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Opgu2N9AFFQ5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "            imgs, labels = imgs.to(torch.device(\"cuda:0\")), labels.to(torch.device(\"cuda:0\"))\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "metadata": {
        "id": "PKrC_3Z9FQ_D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=1024 * 1000,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "model = model.to(torch.device(\"cuda:0\"))\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr6h-LoNFYIO",
        "outputId": "a501922a-f235-4e65-fdde-d6be07839a58"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-12 23:07:49.123229 Epoch 1, Training loss 2.31667160987854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "rm1zz-yVbRyu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list)"
      ],
      "metadata": {
        "id": "RYD44I15dYbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "            imgs, labels = imgs.to(torch.device(\"cuda:0\")), labels.to(torch.device(\"cuda:0\"))\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(\n",
        "                epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "metadata": {
        "id": "bGVQxZAXbU21"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "model.cpu()\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=1024,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net()  #  <2>\n",
        "model = model.to(torch.device(\"cuda:0\"))\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ_j-zT1baHM",
        "outputId": "381f3c0a-f0ce-41dd-e55b-1699b1e33a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.292744524624883\n",
            "Epoch 10, Training loss 1.958862489583541\n",
            "Epoch 20, Training loss 1.7709223129311387\n",
            "Epoch 30, Training loss 1.621062500136239\n",
            "Epoch 40, Training loss 1.4997605207015057\n",
            "Epoch 50, Training loss 1.406019536816344\n",
            "Epoch 60, Training loss 1.337945006331619\n",
            "Epoch 70, Training loss 1.2825653066440506\n",
            "Epoch 80, Training loss 1.233365309481718\n",
            "Epoch 90, Training loss 1.1903399910245622\n",
            "Epoch 100, Training loss 1.150615212868671\n",
            "Epoch 110, Training loss 1.1127490437760645\n",
            "Epoch 120, Training loss 1.0757551850104818\n",
            "Epoch 130, Training loss 1.0398193013911345\n",
            "Epoch 140, Training loss 1.0053152904218556\n",
            "Epoch 150, Training loss 0.9712200578378172\n",
            "Epoch 160, Training loss 0.9402082744909792\n",
            "Epoch 170, Training loss 0.908155155425169\n",
            "Epoch 180, Training loss 0.8790141052129318\n",
            "Epoch 190, Training loss 0.8565642712067585\n",
            "Epoch 200, Training loss 0.8349437494667209\n",
            "Epoch 210, Training loss 0.8112078272566503\n",
            "Epoch 220, Training loss 0.7957611789508742\n",
            "Epoch 230, Training loss 0.7761795520782471\n",
            "Epoch 240, Training loss 0.7644617216927665\n",
            "Epoch 250, Training loss 0.7475728550735785\n",
            "Epoch 260, Training loss 0.7300822029308397\n",
            "Epoch 270, Training loss 0.7147714094239839\n",
            "Epoch 280, Training loss 0.7015505493903647\n",
            "Epoch 290, Training loss 0.6899164939413265\n",
            "Epoch 300, Training loss 0.6769841313362122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=2048,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=2048,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                imgs, labels = imgs.to(torch.device(\"cuda:0\")), labels.to(torch.device(\"cuda:0\"))\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5107I66vreB",
        "outputId": "1fe54cb6-452d-4aa2-8734-177252d1085b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.77\n",
            "Accuracy val: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet"
      ],
      "metadata": {
        "id": "wTo9gJ5Orlha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetRes_10(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
        "                               kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out1 = out\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
        "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "qUSaRu8_Rgg0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "            imgs, labels = imgs.to(torch.device(\"cuda:0\")), labels.to(torch.device(\"cuda:0\"))\n",
        "            outputs = model(imgs)  # <4>\n",
        "\n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "\n",
        "            loss.backward()  # <7>\n",
        "\n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(\n",
        "                epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "metadata": {
        "id": "jFbFkk72rhTF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=4096,\n",
        "                                           shuffle=True)  # <1>\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=4096,\n",
        "                                         shuffle=False)\n",
        "\n",
        "model = NetRes_10(n_chans1=32).to(torch.device(\"cuda:0\"))\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVziyZoeRonW",
        "outputId": "ff653ceb-cd20-443f-eb45-ad063d9377ef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.31243450825031\n",
            "Epoch 10, Training loss 2.2879948982825646\n",
            "Epoch 20, Training loss 2.214522985311655\n",
            "Epoch 30, Training loss 2.0922749042510986\n",
            "Epoch 40, Training loss 1.9942488578649669\n",
            "Epoch 50, Training loss 1.8939153506205633\n",
            "Epoch 60, Training loss 1.8272024943278387\n",
            "Epoch 70, Training loss 1.7720042100319495\n",
            "Epoch 80, Training loss 1.747085919746986\n",
            "Epoch 90, Training loss 1.6687112221351037\n",
            "Epoch 100, Training loss 1.6500557936154878\n",
            "Epoch 110, Training loss 1.6016983619103065\n",
            "Epoch 120, Training loss 1.5889384746551514\n",
            "Epoch 130, Training loss 1.592147552050077\n",
            "Epoch 140, Training loss 1.5214084203426654\n",
            "Epoch 150, Training loss 1.5292710249240582\n",
            "Epoch 160, Training loss 1.5102150256817157\n",
            "Epoch 170, Training loss 1.4817390441894531\n",
            "Epoch 180, Training loss 1.472618213066688\n",
            "Epoch 190, Training loss 1.4305044320913463\n",
            "Epoch 200, Training loss 1.3904639665897076\n",
            "Epoch 210, Training loss 1.3782437489582942\n",
            "Epoch 220, Training loss 1.3870530220178456\n",
            "Epoch 230, Training loss 1.3417422496355498\n",
            "Epoch 240, Training loss 1.3494871304585383\n",
            "Epoch 250, Training loss 1.3143059657170222\n",
            "Epoch 260, Training loss 1.3083796867957482\n",
            "Epoch 270, Training loss 1.2869996382639959\n",
            "Epoch 280, Training loss 1.2878081523455107\n",
            "Epoch 290, Training loss 1.2648389156048114\n",
            "Epoch 300, Training loss 1.246087670326233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                imgs, labels = imgs.to(torch.device(\"cuda:0\")), labels.to(torch.device(\"cuda:0\"))\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCvXt0oFTkeg",
        "outputId": "3ace0fa2-f4ce-481a-c8b3-c3bdcc4d8a2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.56\n",
            "Accuracy val: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn,\n",
        "                        train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=\"cuda:0\")\n",
        "            labels = labels.to(device=\"cuda:0\")\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            l2_lambda = 0.001\n",
        "            l2_norm = sum(p.pow(2.0).sum()\n",
        "                          for p in model.parameters())  # <1>\n",
        "            loss = loss + l2_lambda * l2_norm\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(\n",
        "                epoch,\n",
        "                loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "eNMVZPC_OECv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device=\"cuda:0\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop_l2reg(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyWBOeoGObtG",
        "outputId": "12aaed8d-f70a-44d9-e190-7f523ffb89de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.324833943293645\n",
            "Epoch 10, Training loss 2.220768561730018\n",
            "Epoch 20, Training loss 2.098164906868568\n",
            "Epoch 30, Training loss 2.0166374536661\n",
            "Epoch 40, Training loss 1.9657123639033391\n",
            "Epoch 50, Training loss 1.9271488281396718\n",
            "Epoch 60, Training loss 1.8946729715053852\n",
            "Epoch 70, Training loss 1.8618481250909658\n",
            "Epoch 80, Training loss 1.819174784880418\n",
            "Epoch 90, Training loss 1.7816865627582257\n",
            "Epoch 100, Training loss 1.741009391271151\n",
            "Epoch 110, Training loss 1.712285802914546\n",
            "Epoch 120, Training loss 1.682334909072289\n",
            "Epoch 130, Training loss 1.6567858457565308\n",
            "Epoch 140, Training loss 1.6345323140804584\n",
            "Epoch 150, Training loss 1.6116433418714082\n",
            "Epoch 160, Training loss 1.5992481800226064\n",
            "Epoch 170, Training loss 1.5840789446463952\n",
            "Epoch 180, Training loss 1.570944254214947\n",
            "Epoch 190, Training loss 1.5566963507578924\n",
            "Epoch 200, Training loss 1.5403416248468251\n",
            "Epoch 210, Training loss 1.5310522409585805\n",
            "Epoch 220, Training loss 1.5148938802572398\n",
            "Epoch 230, Training loss 1.5042526813653798\n",
            "Epoch 240, Training loss 1.491365909576416\n",
            "Epoch 250, Training loss 1.4810060812876775\n",
            "Epoch 260, Training loss 1.4746461648207445\n",
            "Epoch 270, Training loss 1.4622658032637377\n",
            "Epoch 280, Training loss 1.4510448987667377\n",
            "Epoch 290, Training loss 1.436914242230929\n",
            "Epoch 300, Training loss 1.4293651214012733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_jcTyGwOvJb",
        "outputId": "442dd590-a22e-44cd-e4e3-c1ff5b20ed90"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.51\n",
            "Accuracy val: 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NetDropout(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv2_dropout = nn.Dropout2d(p=0.3)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = self.conv1_dropout(out)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = self.conv2_dropout(out)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "DcxFzA0Ua-mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetDropout(n_chans1=32).to(device=\"cuda:0\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "id": "6S1wBAW8bBs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "2i2NsC6gbNVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetBatchNorm(nn.Module):\n",
        "    def __init__(self, n_chans1=32):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
        "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1_batchnorm(self.conv1(x))\n",
        "        out = F.max_pool2d(torch.tanh(out), 2)\n",
        "        out = self.conv2_batchnorm(self.conv2(out))\n",
        "        out = F.max_pool2d(torch.tanh(out), 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "WEhEv8T_ePiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetBatchNorm(n_chans1=32).to(device=\"cuda:0\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "metadata": {
        "id": "DYNgxdineT_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "EOpeU9bmeW7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}